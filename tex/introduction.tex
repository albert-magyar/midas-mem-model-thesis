With the slowdown in process technology improvements, architects are
increasingly turning to specialization to deliver advances in
performance and energy efficiency.  Modern SoCs contain a collage of
fixed-function units and specialized accelerators, with
general-purpose application processors consuming a dwindling fraction
of the die.  Heterogeneous specialized systems add new complexity at
all levels of the computing stack, and research into new programming
models, runtimes, and operating systems is expanding.

Architects and systems designers will need a comprehensive set of
simulation technologies to enable this research. Both architectural
and microarchitectural full-system software
simulators will remain important sandboxes for
prototyping new ideas. In many domains, sampling techniques permit the use of
slower but more detailed microarchitectural simulators, providing
greater fidelity without loss of simulation throughput.
Unfortunately, there are many cases in which existing software-based
microarchitectural simulators are too slow, and sampling techniques
fail because samples cannot be reused for changes that have large
impacts on execution behavior.  A few such cases include tuning highly
parallel specialized multiprocessors; runtimes that dynamically
schedule and optimize code based on performance; and hardware-software
co-design flows, where the hardware and software change
simultaneously. In such cases, FPGAs are the only technology that can
provide high-fidelity full-system simulation with low experimental
latency, high throughput, and low cost per simulation
cycle.

FPGA-accelerated simulation has been actively studied over the past
decade, notably in the multi-university RAMP project~\cite{RAMP}, but it has seen little adoption for a number of
reasons:
\begin{enumerate}
%\parskip 0pt
%\itemsep 1pt
\item FPGA-accelerated simulators are difficult to write or modify, and
lengthy compilation times make them onerous to debug.
\item FPGAs have historically been resource-constrained,
limiting the scale of the system under simulation
or incurring the great additional complexity of multi-FPGA partitioning.
\item Purchasing and maintaining an FPGA cluster is prohibitively
expensive.
\end{enumerate}
Fortunately, recent technological advances address the latter two
challenges: FPGAs have been scaling well, providing greater $f_{max}$ and capacity, and
are now widely available as cloud-hosted
resources~\cite{amazonf1}.  Alas, design complexity
challenges remain.

One promising avenue is to automatically generate the FPGA-hosted
components of the simulator from RTL produced by highly configurable
generators such as the Rocket Chip RISC-V SoC generator~\cite{rocketchip}. The
biggest limitation of this approach so far has been modeling the main
memory system.  The DRAM controller RTL, physical interface, and
chip models cannot be simply mapped to the FPGA, so
prior work used simplistic, handwritten RTL models (e.g.,
latency pipes) backed by FPGA-attached DRAM~\cite{khanms}.
In this paper, we address the challenge of flexibly modeling DRAM
memory-systems at greater fidelity.  The techniques we propose can be
applied to modeling other memory types, such as
non-volatile memories, and I/O devices where transformation from ASIC
RTL is difficult or impossible.  This paper makes the following
contributions:

First, we propose separating the concerns of host-platform mapping
from target modeling, by writing the timing model of a
split-timing-functional model as \emph{target-time} RTL.  This
approach makes it considerably easier to describe detailed
timing-model \emph{generators} and allows new users to add new timing
models without a detailed understanding of how the model will be
mapped to the FPGA.

Second, we demonstrate the flexibility of this approach by presenting \PNAME, a
last-level-cache and multi-rank DDR3 timing-model generator with fidelity comparable to
cycle-accurate software-based simulators like DRAMSim2~\cite{dramsim}. \PNAME
instances can be reconfigured without FPGA recompilation and are instrumented
to provide the same performance and power measurements as software-based
simulators.


\section{Collaboration, Previous Publications, and Funding}

This report builds on the work of current and previous students of our group.
The MIDAS project is a multi-student collaboration between myself, Jack Koenig,
Sagar Karandikar, and Donggyu Kim, whose Chisel3 port of Strober~\cite{strober}
constitutes the bulk of the MIDAS code base at the time of writing. The
generator presented here and the RTL libraries used in MIDAS are written in
Chisel3~\cite{chisel} which remains under active development. MIDAS leans
heavily on FIRRTL~\cite{firrtl} to transform source RTL into FPGA-accelerated
models.  Finally, MIDAS depends on the availability of open-source SoC IP as a
source of transformable RTL. Here we use the Rocket-Chip~\cite{rocketchip} SoC
generator and BOOM~\cite{boom} Out-of-Order~(OoO) core generator which
implement the free and open RISC-V ISA~\cite{riscv}.

Work on this memory model began in the fall of 2015, as a course project for
CS252 for which Jack Koenig was my partner. Thereafter, development of the
memory model was driven by MICRO submissions attempts in 2017 and 2018. For the
2017 iteration we had only nascent forms of the DDR models presented herein. I
have my co-authors, Jack Koenig, Chris Celio and especially Martin Maas, who
engineered the DaCapo on Jikes case study, Donggyu Kim, who was reponsible for
running most of the experiments and instrumenting MIDAS so as to make the case
study possible, to thank for getting that half-baked submission out the door.
It proved to be an invaluable source of feedback.  In 2018, FireSim had just
been accepted to ISCA, and Sagar had finished rewriting the manager, which made
collecting the results for the evaluation of this report possible. We'd just
reorganized FireSim, and other repos using MIDAS as a library --- Donggyu Kim
play a key role in getting everything running again.  Howard Mao wrote the
block device and maintained much of the system software.  Jack Koenig wrote
many of the plotting scripts used in the evaluation, and made an eleventh hour
push to get command-trace driven power analysis working, which ultimately
didn't make the paper. Finally, Andrew Waterman had instrumental role in
editing the paper~(and this report) and really helped me keep the whole
operation on track.

This research was partially funded by DARPA Award Number HR0011-12-2-0016,
RISE Lab sponsor Amazon Web Services, ADEPT/ASPIRE
Lab industrial sponsors and affiliates Intel, Google,
Huawei, NVIDIA, Siemens, and SK Hynix. Any opinions, findings,
conclusions, or recommendations in this paper are solely those of the
authors and do not necessarily reflect the position or the policy of
the sponsors.
