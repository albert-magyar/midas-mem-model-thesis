\chapter{Introduction}

For the past half century, Moore's law, and Dennard's law before it, has
delivered incredible improvements in computing performance. The rapid advance
of process technology has proven to be a strong disincentive to building custom
silicon, as any competitive advantage achieved by a custom design in a
particular process technology would eventually be lost to a general-purpose
machine in a built in a newer one. Consequently, advances in computing have
been focused broadly about making programmable, general-purpose machines
faster. For applications that might otherwise see orders of magnitude
improvement with custom silicon over programmable solutions, but lack the
volume to overcome the NRE costs, FPGAs have proven to be an effective stopgap.
Here, FPGAs can reduce NRE costs by an order of magnitude at the expense of an
order of magnitude in area efficiency and clock rate.

With the death of Dennard scaling, and apparent end of Mooreâ€™s law, future
advances in computing performance must come from improvements above the process
technology.  For system designers the risk balance has changed: while the NRE
remains high, custom silicon may now present a lasting competitive advantage.
Application developers will inclined to code against specialized computing
devices -- perhaps, at the expense of code portability -- if they can deliver a
performance improvement that will not be met by a general purpose machine
within the lifetime of the product. Perhaps, the greatest opportunities lie when
both novel hardware and software can be \textit{co-designed} for a particular
application.

Of course, custom silicon is famously inaccessible. The NRE of a new design in
the latest process technology is often quoted as being upwards of \$100
million.  There are many contributing factors, including mask costs, CAD tool
costs, IP costs, and engineering time for design and verification. Hidden from
this perspective, are the costs of developing software for a new design.
Ideally, software development would proceed in parallel to hardware design,
however, lacking sufficiently accurate \textit{full-system simulators} (simulators capable
of executing the entire software stack), software developers are often forced to
develop against a grossly inaccurate model of the machine until silicon is
back. This leads to a serialization of the hardware-software develoment effort
as software must be validated post-silicon, lengthening time-to-market.
Moreover, it precludes effective hardware-software co-design, as it difficult
to reason about hardware and software design tradeoffs if they are each being
evaluating in a different simulation environment.

\textit{MIDAS} (Modeling Infrastructure for Debugging and Simulation) is
Berkeley Architecture Research's answer to the full-system simulation gap.
Building off the findings of the RAMP\cite{ramp} project at Berkeley, MIDAS
differs in primarly in it's objective aims to make  RAMPGold\cite{rampgold} and
DIABLO\cite{diablo}-like simulators easier to build, use and extend. MIDAS
permits co-hosting SW models and FPGA-accelerated RTL models on an arbitrary
\textit{host-platform} consisting of a mix of FPGAs, CPUs. As implementations,
or more complete models of components of the system become available, they can
replace more abstract ones, easing the transistion from an abstract prototype
to a simulator capable of pre-silicon validation. Throughout the whole process
there is a functioning model of the target machine, that is fast enough for
applications developers to code against.

This report presents an important component of the MIDAS environment: an
FPGA-hosted off-chip memory timing model, that is both reconfigurable and
agnostic of the particular FPGA architecture that hosts it. Just as MIDAS
succeeds RAMP, this report succeeds an earlier master's thesis by Asif
Khan\cite{khanmasters} on the same subject. This report differs from that work
in three dimensions:

\begin{enumerate}
    \item The use of a generator to flexibly emit different instances of a timing model.
    \item The ability to integrate this model with models automatically transformed from source RTL.
    \item The degree to which off-chip memory systems are modelled.
\end{enumerate}

\section{Collaboration, Previous Publications, and Funding}

In what I still believe is generally good advice, my undergraduate advisor
Jonathan Rose once suggested to me that one should not couple the success of
one research project to that of another.\\

At Berkeley, we vehemently eschew this notion.\\

This work builds heavily on the work of current and previous students of this
group. The MIDAS project is a multi-student collaboration between myself, Jack
Koenig, Sagar Karandikar, and Donggyu Kim, whose Chisel3 port of
Strober\cite{strober} project constitutes the bulk of the MIDAS code base at
the time of writing. The bulk of this work, and all of the RTL used throughout
MIDAS is written in Chisel3\cite{chisel}. which remains under development at
BAR, with the guidance from SiFive and Google.  MIDAS leans heavily on
FIRRTL\cite{firrtl}(Adam Izraelevitz et al.) to transform source RTL in
FPGA-hosted models. MIDAS depends on the availability of open SoC IP, to build
up a complete target. We rely extensively on the Rocket-Chip\cite{rocketchip},
not only as a generator of RISC-V in-order cores but also as a library of
useful components that are used extensively throughout MIDAS and this work.
Chris Celio's, BOOM(\cite{boom}) OoO core generator is a second important
source of target machines, as one of the early consumers of MIDAS we've
borrowed much of his flow to automatically benchmark our  on the local FPGA
cluster.

\TODO{Funding}

\TODO{What to say about MICRO publication?}


